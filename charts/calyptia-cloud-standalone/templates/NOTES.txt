Calyptia Cloud standalone correctly installed.
{{- if .Values.operator.enabled }}
Calyptia Core Operator correctly installed.
{{- end }}

To get the project token:

kubectl get secret -n {{ .Release.Namespace }} auth-secret -o jsonpath='{.data.ONPREM_CLOUD_API_PROJECT_TOKEN}'| base64 --decode

To create an instance in the cluster run:

helm repo add calyptia https://helm.calyptia.com --force-update
helm repo update

export CLOUD_NAMESPACE={{ .Release.Namespace }}
export INSTANCE_NAMESPACE=core-instance
export INSTANCE_NAME=test
{{- if .Values.operator.enabled }}
helm upgrade --install --namespace "$INSTANCE_NAMESPACE" --create-namespace calyptia-core-instance calyptia/core-instance \
    --set cloudToken="$(kubectl get secret -n "$CLOUD_NAMESPACE" auth-secret -o jsonpath='{.data.ONPREM_CLOUD_API_PROJECT_TOKEN}'| base64 --decode)" \
    --set coreInstance="$INSTANCE_NAME" --set cloudUrl="http://cloud-api.${CLOUD_NAMESPACE}:5000" \
    --debug --wait

If deploying outside of this cluster, replace the 'cloudUrl' with the CLOUD_ENDPOINT above (it must be routable from the source).

Once you have an instance you can also deploy a pipeline via CRD (although this is not recommended)

kubectl apply -f - <<EOF
apiVersion: core.calyptia.com/v1
kind: Pipeline
metadata:
  name: out-test
spec:
  kind: deployment
  hotReload: true
  replicasCount: 1
  fluentbit:
    config: |-
      pipeline:
        inputs:
          - name: dummy
            tag: dummy
        outputs:
          - name: stdout
            match: "*"
EOF

This will spin up a pod to handle the pipeline as a test, however this should be done via the Calyptia CLI or UI to properly control and manage it.

{{- else }}
export INSTANCE_TAG=test

helm upgrade --install --namespace "$INSTANCE_NAMESPACE" --create-namespace calyptia-core calyptia/core \
    --set project_token="$(kubectl get secret -n "$CLOUD_NAMESPACE" auth-secret -o jsonpath='{.data.ONPREM_CLOUD_API_PROJECT_TOKEN}'| base64 --decode)" \
    --set name="$INSTANCE_NAME" --set core_instance_tags="$INSTANCE_TAG" --set api_url="http://cloud-api.$CLOUD_NAMESPACE:5000" \
    --debug --wait

If deploying outside of this cluster, replace the 'api_url' with the CLOUD_ENDPOINT above (it must be routable from the source).
{{- end }}

Run the following to get the services:

kubectl get -n {{ .Release.Namespace }} svc

ClusterIP services will need port-forwarding/ingress to use externally.

{{- if contains "LoadBalancer" .Values.cloudApi.service.type }}

* Cloud-API:

IP=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=cloud-api' -o=jsonpath='{.items..status.loadBalancer.ingress[0].ip}')
PORT=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=cloud-api' -o=jsonpath='{.items..spec.ports[0].port}')
CLOUD_ENDPOINT="http://${IP}:${PORT}
curl -sSfL "$CLOUD_ENDPOINT"
{{- end }}
{{- if contains "LoadBalancer" .Values.frontend.service.type }}

* Core/UI:

IP=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=core' -o=jsonpath='{.items..status.loadBalancer.ingress[0].ip}')
PORT=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=core' -o=jsonpath='{.items..spec.ports[0].port}')
UI_ENDPOINT="http://${IP}:${PORT}
{{- end }}
{{- if contains "LoadBalancer" .Values.vivo.service.type }}

* Vivo

IP=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=vivo' -o=jsonpath='{.items..status.loadBalancer.ingress[0].ip}')
PORT=$(kubectl get -n {{ .Release.Namespace }} svc -l 'app.kubernetes.io/component=vivo' -o=jsonpath='{.items..spec.ports[0].port}')
VIVO_ENDPOINT="http://${IP}:${PORT}/vivo
{{- end }}

{{- if .Values.monitoring.grafana }}

* Grafana

The admin login is in the 'calyptia-cloud-grafana' secret:

kubectl get secret -n {{ .Release.Namespace }} calyptia-cloud-grafana -o jsonpath='{.data.admin-password}'| base64 --decode

To access it, port-forward the 'calyptia-cloud-grafana' service on port 80, e.g. for http://localhost:3000

kubectl port-forward -n {{ .Release.Namespace }} svc/calyptia-cloud-grafana 3000:80

{{- end }}
{{- if .Values.monitoring.grafana }}

* Monitoring

A Core Fluent Bit daemonset is deployed to gather logs and node metrics to send to the supported outputs.
This generates a K8S config map:

kubectl describe -n {{ .Release.Namespace }} configmap monitoring-daemonset

A different configuration can be provided via the '.monitoring-daemonset.existingConfigMap' Helm chart value.

A Core Fluent Bit deployment is also provided to gather service-level metrics to send to the supported outputs.
This generates a K8S config map:

kubectl describe -n {{ .Release.Namespace }} configmap monitoring-aggregator

A different configuration can be provided via the '.monitoring-aggregator.existingConfigMap' Helm chart value.

Each of these provides Prometheus metrics via port 2021 `/metrics` endpoint.
{{- end }}
