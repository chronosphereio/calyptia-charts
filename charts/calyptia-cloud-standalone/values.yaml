# Initial placeholder for config options for the Helm chart

commonLabels: {}
commonAnnotations: {}
nameOverride: ""
fullnameOverride: ""
#
## RBAC configuration
## @param rbac.create Specifies whether RBAC resources should be created
##
rbac:
  create: true
#
#
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry and imagePullSecrets
## @section Global parameters
## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  # Note that this overrides any specific ones below
  imageRegistry: ""
  # Add any custom pull secrets required
  imagePullSecrets:
    - regcreds
  storageClass: ""
  pullPolicy: IfNotPresent
#
## Define this to automatically set up image pull secrets
# imageCredentials:
#   secretName: regcreds
#   registry: ghcr.io
#   username: calyptia-ci
#   password: <TOKEN>
#   email: ci@calyptia.com
#
# Shared authentication for back and front ends
authentication:
  secret:
    name: auth-secret
    # Only supported mode is singleTenant
    # mode: singleTenant
cloudApi:
  enabled: true
  service:
    type: LoadBalancer
    port: 5000
  name: cloud-api
  resources:
    limits:
      memory: 500Mi
      cpu: 500m
    requests: {}
  startupProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 30
    periodSeconds: 10
  readinessProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 3
    periodSeconds: 60
  livenessProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 7
    periodSeconds: 60
  images:
    cloud:
      registry: ghcr.io
      repository: calyptia/cloud
      tag: 1.6.8
      pullSecrets: []
    kubectl:
      registry: docker.io
      repository: bitnami/kubectl
      tag: 1.25.12
      pullSecrets: []
    postgres:
      registry: docker.io
      repository: postgres
      tag: 15.3
      pullSecrets: []
    influxdb:
      registry: docker.io
      repository: influxdb
      tag: 2.7.1
      pullSecrets: []
  serviceAccount:
    create: true
    name: ""
    annotations: {}
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetMemoryUtilizationPercentage: 50
    targetCPUUtilizationPercentage: 50
  # All influx config
  influxdb:
    # Disable if providing separately
    enabled: true
    # Set this if providing separately
    # server: http://influxdb:8086
    replicas: 1
    resources:
      limits:
        memory: 500Mi
        cpu: 500m
      requests: {}
  # All postgres config
  postgres:
    # Disable if providing separately
    enabled: true
    # Set this if providing separately
    # connectionString: postgresql://postgres@postgres:5432?sslmode=disable
    replicas: 1
    resources:
      limits:
        memory: 500Mi
        cpu: 500m
      requests: {}
  # Used for creating the auth-secret
  kubectl:
    resources:
      limits: {}
      requests: {}
#
# Core instances/operator running in same cluster
operator:
  # Enable to deploy the Core operator
  enabled: true
#
# Core UI
frontend:
  enabled: true
  service:
    type: LoadBalancer
    port: 3000
  name: core
  images:
    frontend:
      registry: ghcr.io
      repository: calyptia/frontend
      tag: 1.5.3
      pullSecrets: []
    luaSandbox:
      registry: ghcr.io
      repository: calyptia/cloud-lua-sandbox
      tag: 2.2.0
      pullSecrets: []
  serviceAccount:
    create: true
    name: ""
    annotations: {}
  resources:
    limits:
      memory: 500Mi
      cpu: 500m
    requests: {}
  startupProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 30
    periodSeconds: 10
  readinessProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 10
    periodSeconds: 60
  livenessProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 30
    periodSeconds: 60
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetMemoryUtilizationPercentage: 50
    targetCPUUtilizationPercentage: 50
  luaSandbox:
    replicas: 1
    resources:
      limits:
        memory: 500Mi
        cpu: 500m
      requests: {}
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 5
      targetMemoryUtilizationPercentage: 50
      targetCPUUtilizationPercentage: 50
  kubectl:
    resources:
      limits: {}
      requests: {}
vivo:
  enabled: true
  service:
    type: LoadBalancer
    port: 3000
  name: vivo
  images:
    vivo:
      registry: docker.io
      repository: calyptia/vivo
      tag: 3.0.1
      pullSecrets: []
  resources:
    requests:
      memory: "64Mi"
      cpu: "250m"
    limits:
      memory: "128Mi"
      cpu: "500m"
  readinessProbe:
    httpGet:
      path: /api/v1/health
      port: fluent-bit
    failureThreshold: 3
    periodSeconds: 5
  livenessProbe:
    httpGet:
      path: /api/v1/health
      port: fluent-bit
    failureThreshold: 5
    periodSeconds: 5
ingress:
  enabled: false
  port: 80
  images:
    nginx:
      registry: docker.io
      repository: nginx
      tag: 1.25.1
  config:
    # Switch to individual sidecars as well per pod
    nginx: |
      server {
        listen {{ .Values.ingress.port }};
        server_name localhost gateway.{{ .Release.Namespace }};

        location /vivo {
          proxy_pass http://vivo.{{ .Release.Namespace }}:{{ .Values.vivo.service.port }}/vivo;
        }

        location ~ /(healthz|prometheus_metrics|v\d/.*) {
          proxy_pass http://cloud-api.{{ .Release.Namespace }}:{{ .Values.cloudApi.service.port }};
        }

        location /jsonrpc {
          proxy_pass http://cloud-lua-sandbox.{{ .Release.Namespace }}:5555/jsonrpc;
        }

        location / {
          proxy_pass http://core.{{ .Release.Namespace }}:{{ .Values.frontend.service.port }};
        }
      }
  resources:
    limits: {}
    requests: {}
#
monitoring:
  fluentBit: true
  grafana: false
#
# Dependent chart config: https://github.com/calyptia/charts/tree/master/charts/core-crd
core-crd:
  images:
    hotReload:
      registry: ghcr.io
      repository: calyptia/configmap-reload
      tag: 0.11.1
      pullSecrets: []
    fluentBit:
      registry: ghcr.io
      repository: calyptia/core/calyptia-fluent-bit
      tag: 23.11.3
      pullSecrets: []
    ingestCheck:
      registry: ghcr.io
      repository: calyptia/core/ingest-check
      tag: 0.0.7
      pullSecrets: []
#
# Dependent chart config: https://github.com/calyptia/charts/tree/master/charts/core-operator
core-operator:
  images:
    operator:
      registry: ghcr.io
      repository: calyptia/core-operator
      tag: 2.0.25
      pullSecrets: []
    hotReload:
      registry: ghcr.io
      repository: calyptia/configmap-reload
      tag: 0.11.1
      pullSecrets: []
    # The following are not chart parameters but simplify building the offline packages
    toCloud:
      registry: ghcr.io
      repository: calyptia/core-operator/sync-to-cloud
      tag: 2.0.25
      pullSecrets: []
    fromCloud:
      registry: ghcr.io
      repository: calyptia/core-operator/sync-from-cloud
      tag: 2.0.25
      pullSecrets: []
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/"
    prometheus.io/port: '8081'
    # Set up Dynatrace scraping
    metrics.dynatrace.com/scrape: "true"
    metrics.dynatrace.com/path: "/"
    metrics.dynatrace.com/port: '8081'
# Dependent chart so have to use the values as defined there
loki-stack:
  enterprise:
    enabled: false
  loki:
    enabled: true
    auth_enabled: false
    # Note this uses the same global.override support we do
    # image:
    #   registry: docker.io
    #   repository: grafana/loki
    #   tag: 5.12.0
  minio:
    enabled: true
    # image:
    #   repository: quay.io/minio/minio
    #   tag: 4.0.12
    #   pullPolicy: IfNotPresent

    imagePullSecrets:
      - regcreds
  fluent-bit:
    enabled: false
  grafana:
    enabled: true
  promtail:
    enabled: false
  filebeat:
    enabled: false
  logstash:
    enabled: false
  prometheus:
    enabled: true
    alertmanager:
      enabled: true
    kube-state-metrics:
      enabled: true
    prometheus-node-exporter:
      enabled: true
    prometheus-pushgateway:
      enabled: true
    server:
      enabled: true
      extraFlags:
        - web.enable-lifecycle
        - web.enable-remote-write-receiver
      persistentVolume:
        enabled: false
monitoring-daemonset:
  pullSecrets:
    - regcreds
  image:
    # Have to customise separately
    repository: ghcr.io/calyptia/core/calyptia-fluent-bit
    tag: 23.11.3
    pullPolicy: IfNotPresent
  # Modify this to use any other CM you want
  existingConfigMap: monitoring-daemonset
  extraPorts:
    - port: 2021
      containerPort: 2021
      name: metrics
      protocol: TCP
  securityContext:
    runAsNonRoot: false
    runAsUser: 0
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  podAnnotations:
    # Exclude our own logs
    fluentbit.io/exclude: "true"
    # Set up Prometheus scraping
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics"
    prometheus.io/port: '2021'
    # Set up Dynatrace scraping
    metrics.dynatrace.com/scrape: "true"
    metrics.dynatrace.com/path: "/metrics"
    metrics.dynatrace.com/port: '2021'
  podLabels: {}
  flush: 1
  logLevel: info
  env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
  daemonSetVolumes:
    - name: varlog
      hostPath:
        path: /var/log/
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
    - name: etcmachineid
      hostPath:
        path: /etc/machine-id
        type: File
    - name: hostproc
      hostPath:
        path: /proc
    - name: hostsys
      hostPath:
        path: /sys
  daemonSetVolumeMounts:
    - name: varlog
      mountPath: /var/log/
      readOnly: true
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true
    - name: etcmachineid
      mountPath: /etc/machine-id
      readOnly: true
    - name: hostproc
      mountPath: /host/proc
      readOnly: true
    - name: hostsys
      mountPath: /host/sys
      readOnly: true
monitoring-aggregator:
  kind: Deployment
  replicaCount: 1
  pullSecrets:
    - regcreds
  image:
    repository: ghcr.io/calyptia/core/calyptia-fluent-bit
    tag: 23.11.3
    pullPolicy: IfNotPresent
  # Modify this to use any other CM you want
  existingConfigMap: monitoring-aggregator
  extraPorts:
    - port: 2021
      containerPort: 2021
      name: metrics
      protocol: TCP
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  podLabels: {}
  flush: 1
  logLevel: info
  # We want to scrape the service, not the pods
  service:
    annotations:
      # Set up Prometheus scraping
      prometheus.io/scrape: "true"
      prometheus.io/path: "/metrics"
      prometheus.io/port: '2021'
      # Set up Dynatrace scraping
      metrics.dynatrace.com/scrape: "true"
      metrics.dynatrace.com/path: "/metrics"
      metrics.dynatrace.com/port: '2021'
